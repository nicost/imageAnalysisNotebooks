{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1c8490-8810-4d7a-9eb6-e245ac3a9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import roifile\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d71de52-bb48-4c45-b3cf-b8c4fbc5cb08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_imagej_rois(file_path):\n",
    "    \"\"\"\n",
    "    Reads ImageJ ROI files (.roi or .zip) and extracts ROI information,\n",
    "    including x, y coordinates.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the ImageJ ROI file (e.g., 'my_rois.roi'\n",
    "                         or 'my_rois.zip').\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list where each dictionary represents an ROI.\n",
    "                      Each dictionary contains at least 'label' and 'coordinates'.\n",
    "                      The structure of 'coordinates' depends on the ROI type.\n",
    "                      Returns an empty list if no ROIs are found or file is invalid.\n",
    "    \"\"\"\n",
    "    roi_data = []\n",
    "\n",
    "    try:\n",
    "        # roifile.ImagejRoi.fromfile() is the correct method for reading a single .roi file.\n",
    "        # For .zip files, it correctly detects and returns a list of ROI objects.\n",
    "        # This simplifies the initial reading step significantly.\n",
    "        rois = roifile.ImagejRoi.fromfile(file_path)\n",
    "\n",
    "        # Ensure 'rois' is always a list for consistent processing\n",
    "        if not isinstance(rois, list):\n",
    "            rois = [rois] # Wrap single ROI object in a list\n",
    "\n",
    "        for roi_obj in rois:\n",
    "            coords = get_roi_coordinates(roi_obj)\n",
    "            if coords is not None:\n",
    "                # Use roi_obj.name for label, fallback if name is not explicitly set\n",
    "                label = roi_obj.name if roi_obj.name else f\"ROI_{rois.index(roi_obj) + 1}\"\n",
    "                # If it's a single .roi file and no name, use filename without extension\n",
    "                if not roi_obj.name and len(rois) == 1:\n",
    "                    label = os.path.basename(file_path).replace('.roi', '')\n",
    "\n",
    "                roi_data.append({\n",
    "                    'label': label,\n",
    "                    'roi_type': roi_obj.roitype.name, # Use .name for string representation\n",
    "                    'coordinates': coords\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    return roi_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e87079-10f8-45d0-8079-9a930b9f33d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_roi_coordinates(roi_obj):\n",
    "    \"\"\"\n",
    "    Extracts coordinates from a roifile.ImagejRoi object based on its type.\n",
    "\n",
    "    Args:\n",
    "        roi_obj (roifile.ImagejRoi): An ROI object read by roifile.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray or None: A NumPy array of (x, y) coordinates for polygon,\n",
    "                               freehand, line, or point ROIs.\n",
    "                               For rectangular or oval ROIs, it returns the bounding box.\n",
    "                               Returns None for unsupported ROI types or if coordinates are not applicable.\n",
    "    \"\"\"\n",
    "    roi_type = roi_obj.roitype\n",
    "\n",
    "    if roi_type in [roifile.ROI_TYPE.POLYGON, \n",
    "                    roifile.ROI_TYPE.FREELINE, roifile.ROI_TYPE.POINT]:\n",
    "        # For polygon, freehand, freehandline, and point, the 'points' attribute contains vertices\n",
    "        # Or, the roi_obj itself can be iterated if it's a point ROI.\n",
    "        # The coordinates() method is generally the way to get geometric points.\n",
    "        return roi_obj.coordinates()\n",
    "    elif roi_type in [roifile.ROI_TYPE.RECT, roifile.ROI_TYPE.OVAL]:\n",
    "        # Rectangular/Oval ROI: defined by bounding box [left, top, right, bottom]\n",
    "        # Coordinates can be represented as top-left and bottom-right corners\n",
    "        return np.array([[roi_obj.left, roi_obj.top],\n",
    "                         [roi_obj.right, roi_obj.bottom]])\n",
    "    elif roi_type == roifile.ROI_TYPE.LINE:\n",
    "        # Line ROI: x1, y1, x2, y2\n",
    "        return np.array([[roi_obj.x1, roi_obj.y1],\n",
    "                         [roi_obj.x2, roi_obj.y2]])\n",
    "    else:\n",
    "        print(f\"Warning: ROI type '{roi_type.name}' ({roi_type}) not explicitly handled for coordinate extraction. \"\n",
    "              \"Check roifile documentation for how to access its specific data. ROI Label: {roi_obj.name}\")\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79b39460-ce72-4c2f-8075-1cb5b6b79203",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_circular_mask(shape: Tuple[int, int], center: Tuple[int, int], radius: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a circular mask for the given shape and center coordinates.\n",
    "    \n",
    "    Args:\n",
    "        shape: Shape of the image (height, width)\n",
    "        center: Center coordinates (x, y)\n",
    "        radius: Radius of the circle\n",
    "    \n",
    "    Returns:\n",
    "        Boolean mask where True indicates pixels inside the circle\n",
    "    \"\"\"\n",
    "    y, x = np.ogrid[:shape[0], :shape[1]]\n",
    "    cx, cy = center\n",
    "    \n",
    "    # Calculate distance from center\n",
    "    distance = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "    \n",
    "    # Create circular mask\n",
    "    mask = distance <= radius\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a3a617-a2d3-4a6f-98d2-b636c37e86ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_circular_intensities(image: np.ndarray, coordinates: List[Tuple[int, int]], \n",
    "                               radius: float = 5.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract mean intensities from circular regions around given coordinates.\n",
    "    \n",
    "    Args:\n",
    "        image: 3D numpy array of shape (t, x, y)\n",
    "        coordinates: List of (x, y) coordinate tuples\n",
    "        radius: Radius of the circular region\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array of shape (n_coordinates, n_timepoints) containing mean intensities\n",
    "    \"\"\"\n",
    "    n_timepoints, height, width = image.shape\n",
    "    n_coords = len(coordinates)\n",
    "    \n",
    "    # Initialize result array\n",
    "    intensities = np.zeros((n_coords, n_timepoints))\n",
    "    \n",
    "    # Process each coordinate\n",
    "    for coord_idx, (x, y) in enumerate(coordinates):\n",
    "        # Check if coordinates are within image bounds\n",
    "        if x < 0 or x >= width or y < 0 or y >= height:\n",
    "            print(f\"Warning: Coordinate ({x}, {y}) is outside image bounds\")\n",
    "            intensities[coord_idx, :] = np.nan\n",
    "            continue\n",
    "        \n",
    "        # Create circular mask\n",
    "        mask = create_circular_mask((height, width), (x, y), radius)\n",
    "        \n",
    "        # Check if mask contains any pixels\n",
    "        if not np.any(mask):\n",
    "            print(f\"Warning: No pixels found in circle at ({x}, {y}) with radius {radius}\")\n",
    "            intensities[coord_idx, :] = np.nan\n",
    "            continue\n",
    "        \n",
    "        # Extract mean intensity for each time point\n",
    "        for t in range(n_timepoints):\n",
    "            masked_pixels = image[t][mask]\n",
    "            intensities[coord_idx, t] = np.mean(masked_pixels)\n",
    "    \n",
    "    return intensities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e98c7d3-a1ed-45f5-a10f-114eaac91499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intensity_timeseries(name: str, intensities: np.ndarray, coordinates: List[Tuple[int, int]], \n",
    "                            radius: float, time_interval: float = 1.0, figsize: Tuple[int, int] = (12, 8),\n",
    "                             y_lim: Tuple[int, int] = (0.3, 1.1) ):\n",
    "    \"\"\"\n",
    "    Plot intensity time series for each coordinate, normalized by the first time point.\n",
    "    \n",
    "    Args:\n",
    "        intensities: 2D array of shape (n_coordinates, n_timepoints)\n",
    "        coordinates: List of (x, y) coordinate tuples\n",
    "        radius: Radius used for extraction\n",
    "        time_interval: Time interval between data points in seconds\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    n_coords, n_timepoints = intensities.shape\n",
    "    time_points = np.arange(n_timepoints) * time_interval\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Plot each coordinate's time series\n",
    "    for i, (x, y) in enumerate(coordinates):\n",
    "        # Normalize by the first time point\n",
    "        #first_point = intensities[i, 0]\n",
    "        #if not np.isnan(first_point) and first_point != 0:\n",
    "        #    normalized_intensities = intensities[i, :] / first_point\n",
    "        #else:\n",
    "        #    # Handle edge case where first point is NaN or zero\n",
    "        #    normalized_intensities = np.full_like(intensities[i, :], np.nan)\n",
    "            \n",
    "        plt.plot(time_points, intensities[i, :], \n",
    "                marker='o', markersize=3, linewidth=1.5,\n",
    "                label=f'({x}, {y})')\n",
    "    \n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Normalized Intensity (F/F₀)')\n",
    "    plt.ylim(y_lim)\n",
    "    plt.title(name + f'-Normalized Intensity Time Series (Radius: {radius})')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057527b0-90ae-4979-8dd7-209cdccf28a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_exponential_to_average(normalized_array: np.ndarray, \n",
    "                              fit_type: str = 'decay',\n",
    "                              return_stats: bool = False):\n",
    "    \"\"\"\n",
    "    Fit the average of a normalized array to an exponential function.\n",
    "    \n",
    "    Parameters:\n",
    "    normalized_array (np.ndarray): 2D normalized intensity array with shape (n_series, n_timepoints)\n",
    "                                  e.g., (8, 200) where 8 is number of timeseries, 200 is timepoints\n",
    "    fit_type (str): Type of exponential fit - 'decay', 'growth', or 'general'\n",
    "    return_stats (bool): If True, return additional fit statistics\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (fitted_parameters, time_points, fitted_curve, [optional: fit_stats])\n",
    "    \n",
    "    a: amplitude/scaling factor\n",
    "    b: rate constant (positive for growth, negative for decay)\n",
    "    c: offset/baseline level\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate average across all rows (timeseries) - axis=0 averages across series\n",
    "    average_signal = np.mean(normalized_array, axis=0)\n",
    "    \n",
    "    # Create time points (assuming unit time steps)\n",
    "    time_points = np.arange(len(average_signal))\n",
    "    \n",
    "    # Define exponential functions\n",
    "    def exponential_decay(t, a, b, c):\n",
    "        \"\"\"a * exp(-b * t) + c\"\"\"\n",
    "        return a * np.exp(-b * t) + c\n",
    "    \n",
    "    def exponential_growth(t, a, b, c):\n",
    "        \"\"\"a * exp(b * t) + c\"\"\"\n",
    "        return a * np.exp(b * t) + c\n",
    "    \n",
    "    def exponential_general(t, a, b, c):\n",
    "        \"\"\"a * exp(b * t) + c (b can be positive or negative)\"\"\"\n",
    "        return a * np.exp(b * t) + c\n",
    "    \n",
    "    # Select function and initial parameters based on fit_type\n",
    "    if fit_type == 'decay':\n",
    "        func = exponential_decay\n",
    "        # Initial guess: start high, decay to baseline\n",
    "        p0 = [average_signal[0] - average_signal[-1], 0.01, average_signal[-1]]\n",
    "    elif fit_type == 'growth':\n",
    "        func = exponential_growth\n",
    "        # Initial guess: start low, grow to final value\n",
    "        p0 = [average_signal[-1] - average_signal[0], 0.01, average_signal[0]]\n",
    "    elif fit_type == 'general':\n",
    "        func = exponential_general\n",
    "        # Initial guess: let it figure out growth or decay\n",
    "        if average_signal[-1] > average_signal[0]:\n",
    "            p0 = [average_signal[-1] - average_signal[0], 0.01, average_signal[0]]\n",
    "        else:\n",
    "            p0 = [average_signal[0] - average_signal[-1], -0.01, average_signal[-1]]\n",
    "    else:\n",
    "        raise ValueError(\"fit_type must be 'decay', 'growth', or 'general'\")\n",
    "    \n",
    "    try:\n",
    "        # Perform the fit\n",
    "        popt, pcov = curve_fit(func, time_points, average_signal, p0=p0, maxfev=10000)\n",
    "        \n",
    "        # Generate fitted curve\n",
    "        fitted_curve = func(time_points, *popt)\n",
    "        \n",
    "        # Calculate fit statistics if requested\n",
    "        if return_stats:\n",
    "            # R-squared\n",
    "            ss_res = np.sum((average_signal - fitted_curve) ** 2)\n",
    "            ss_tot = np.sum((average_signal - np.mean(average_signal)) ** 2)\n",
    "            r_squared = 1 - (ss_res / ss_tot)\n",
    "            \n",
    "            # Parameter errors (standard deviation)\n",
    "            param_errors = np.sqrt(np.diag(pcov))\n",
    "            \n",
    "            # Root mean square error\n",
    "            rmse = np.sqrt(np.mean((average_signal - fitted_curve) ** 2))\n",
    "            \n",
    "            fit_stats = {\n",
    "                'r_squared': r_squared,\n",
    "                'rmse': rmse,\n",
    "                'parameter_errors': param_errors,\n",
    "                'covariance_matrix': pcov\n",
    "            }\n",
    "            \n",
    "            return popt, time_points, fitted_curve, average_signal, fit_stats\n",
    "        \n",
    "        return popt, time_points, fitted_curve, average_signal\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Fitting failed: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0296165-1265-453d-b458-2f90ad172c84",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_exponential_fit(time_points, average_signal, fitted_curve, parameters, \n",
    "                        fit_type='decay', fit_stats=None):\n",
    "    \"\"\"\n",
    "    Plot the original data and exponential fit.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_points, average_signal, 'bo-', label='Average Signal', markersize=4)\n",
    "    plt.plot(time_points, fitted_curve, 'r-', label=f'Exponential Fit ({fit_type})', linewidth=2)\n",
    "    \n",
    "    # Add parameter info to plot\n",
    "    if fit_type == 'decay':\n",
    "        plt.title(f'Exponential Decay Fit: y = {parameters[0]:.3f} * exp(-{parameters[1]:.3f} * t) + {parameters[2]:.3f}')\n",
    "    elif fit_type == 'growth':\n",
    "        plt.title(f'Exponential Growth Fit: y = {parameters[0]:.3f} * exp({parameters[1]:.3f} * t) + {parameters[2]:.3f}')\n",
    "    else:\n",
    "        sign = '+' if parameters[1] >= 0 else ''\n",
    "        plt.title(f'Exponential Fit: y = {parameters[0]:.3f} * exp({sign}{parameters[1]:.3f} * t) + {parameters[2]:.3f}')\n",
    "    \n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Normalized Intensity')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add fit statistics if available\n",
    "    if fit_stats:\n",
    "        textstr = f'R² = {fit_stats[\"r_squared\"]:.4f}\\nRMSE = {fit_stats[\"rmse\"]:.4f}'\n",
    "        plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2307d08-1a8f-4509-bc03-92e492477b9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def exponential(x, parameters):\n",
    "    return parameters[0] * np.exp(-parameters[1] * x) + parameters[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79957a8-e9a0-4906-97d5-a8aab961f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_for_bleaching(input_array: np.ndarray, parameters):\n",
    "    correction_array=np.ones((1, input_array.shape[1]))\n",
    "    for x in range(input_array.shape[1]) :\n",
    "        correction_array[0, x] = exponential(x, parameters)\n",
    "    result = input_array / correction_array\n",
    "    return result, correction_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f191ed67-10e0-411c-bb3d-7a8ba464fbe8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def analyze_circular_regions(image: np.ndarray, coordinates: List[Tuple[int, int]], \n",
    "                           radius: float = 5.0, time_interval: float = 1.0, plot: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Complete analysis pipeline: extract intensities and optionally plot results.\n",
    "    \n",
    "    Args:\n",
    "        image: 3D numpy array of shape (t, x, y)\n",
    "        coordinates: List of (x, y) coordinate tuples\n",
    "        radius: Radius of the circular region\n",
    "        time_interval: Time interval between data points in seconds\n",
    "        plot: Whether to create a plot\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array of intensities\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing {len(coordinates)} coordinates with radius {radius}\")\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    \n",
    "    # Extract intensities\n",
    "    intensities = extract_circular_intensities(image, coordinates, radius)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nIntensity Statistics:\")\n",
    "    print(f\"Shape: {intensities.shape}\")\n",
    "    print(f\"Mean across all: {np.nanmean(intensities):.3f}\")\n",
    "    print(f\"Std across all: {np.nanstd(intensities):.3f}\")\n",
    "    print(f\"Min: {np.nanmin(intensities):.3f}\")\n",
    "    print(f\"Max: {np.nanmax(intensities):.3f}\")\n",
    "    \n",
    "    # Plot if requested\n",
    "    if plot:\n",
    "        plot_intensity_timeseries(intensities, coordinates, radius, time_interval)\n",
    "    \n",
    "    return intensities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15505fb9-faf0-4f45-b93d-62b4a69d928b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def normalized_intensity_timeseries(intensities: np.ndarray, \n",
    "                                   number_of_first_frames_to_set_to_one: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize each row of a 2D intensity array by the average of the first n frames.\n",
    "    \n",
    "    Parameters:\n",
    "    intensities (np.ndarray): 2D numpy array where each row represents a timeseries\n",
    "                             (e.g., shape (200, 8) means 200 timepoints, 8 series)\n",
    "    number_of_first_frames_to_set_to_one (int): Number of first frames to use for \n",
    "                                               calculating the baseline average\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Normalized intensity array with same shape as input\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if len(intensities.shape) != 2:\n",
    "        raise ValueError(\"intensities must be a 2D array\")\n",
    "    \n",
    "    if number_of_first_frames_to_set_to_one <= 0:\n",
    "        raise ValueError(\"number_of_first_frames_to_set_to_one must be positive\")\n",
    "    \n",
    "    if number_of_first_frames_to_set_to_one > intensities.shape[0]:\n",
    "        raise ValueError(f\"number_of_first_frames_to_set_to_one ({number_of_first_frames_to_set_to_one}) \"\n",
    "                        f\"cannot exceed number of timepoints ({intensities.shape[0]})\")\n",
    "    \n",
    "    # Calculate baseline average for each column (timeseries)\n",
    "    # Take the first n rows and compute mean along axis 0 (across timepoints)\n",
    "    baseline_averages = np.mean(intensities[:, :number_of_first_frames_to_set_to_one], axis=1)\n",
    "    \n",
    "    # Check for zero averages to avoid division by zero\n",
    "    if np.any(baseline_averages == 0):\n",
    "        raise ValueError(\"Some baseline averages are zero, cannot normalize\")\n",
    "    \n",
    "    # Normalize each column by its baseline average\n",
    "    # Broadcasting will handle the division across all rows\n",
    "    normalized = (intensities.T / baseline_averages).T\n",
    "    \n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e113d61-859d-4331-ad47-613b98e869b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_fitting(): # Example usage\n",
    "    # Create sample normalized data (simulating exponential decay)\n",
    "    # Now with shape (n_series, n_timepoints) = (8, 200)\n",
    "    np.random.seed(42)\n",
    "    n_timepoints = 200\n",
    "    n_series = 8\n",
    "    \n",
    "    # Generate synthetic data with exponential decay + noise\n",
    "    t = np.arange(n_timepoints)\n",
    "    true_signal = 2.0 * np.exp(-0.03 * t) + 0.5  # True exponential decay\n",
    "    \n",
    "    # Add some variation across different series and noise\n",
    "    sample_data = np.zeros((n_series, n_timepoints))\n",
    "    for i in range(n_series):\n",
    "        # Each series has slight variations\n",
    "        variation = np.random.normal(1.0, 0.1)\n",
    "        noise = np.random.normal(0, 0.05, n_timepoints)\n",
    "        sample_data[i, :] = true_signal * variation + noise\n",
    "    \n",
    "    print(\"Sample data shape:\", sample_data.shape)\n",
    "    print(\"Data range:\", np.min(sample_data), \"to\", np.max(sample_data))\n",
    "    \n",
    "    # Fit exponential decay\n",
    "    try:\n",
    "        params, time_pts, fit_curve, avg_signal, stats = fit_exponential_to_average(\n",
    "            sample_data, fit_type='decay', return_stats=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFit Results:\")\n",
    "        print(f\"Parameters [a, b, c]: {params}\")\n",
    "        print(f\"Function: y = {params[0]:.3f} * exp(-{params[1]:.3f} * t) + {params[2]:.3f}\")\n",
    "        print(f\"R-squared: {stats['r_squared']:.4f}\")\n",
    "        print(f\"RMSE: {stats['rmse']:.4f}\")\n",
    "        \n",
    "        # Create and show plot\n",
    "        fig = plot_exponential_fit(time_pts, avg_signal, fit_curve, params, 'decay', stats)\n",
    "        plt.show()\n",
    "        \n",
    "        # Compare with true parameters\n",
    "        print(f\"\\nTrue parameters were: a=2.0, b=0.03, c=0.5\")\n",
    "        print(f\"Fitted parameters: a={params[0]:.3f}, b={params[1]:.3f}, c={params[2]:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during fitting: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa6e7e5c-fcc4-4185-b68b-4667f81db7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_recovery_function(intensity_array: np.ndarray, \n",
    "                         time_interval: float,\n",
    "                         return_stats: bool = False,\n",
    "                         plot_results: bool = False):\n",
    "    \"\"\"\n",
    "    Fit recovery data to F(t) = A * (1 - exp(-t/τ)) starting from the lowest intensity point, or point 15, whichever comes first\n",
    "    \n",
    "    Parameters:\n",
    "    intensity_array (np.ndarray): 2D array of shape (x, y) where x is series number,\n",
    "                                 y is intensity as function of time\n",
    "    time_interval: Time interval between data points in seconds                             \n",
    "    return_stats (bool): If True, return additional fit statistics\n",
    "    plot_results (bool): If True, create plots showing fits\n",
    "    \n",
    "    Returns:\n",
    "    dict: Contains fitted parameters and statistics for each series\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(intensity_array.shape) != 2:\n",
    "        raise ValueError(\"Input must be a 2D array\")\n",
    "    \n",
    "    n_series, n_timepoints = intensity_array.shape\n",
    "    \n",
    "    # Define the recovery function\n",
    "    def recovery_function(t, A, tau):\n",
    "        \"\"\"F(t) = A * (1 - exp(-t/tau))\"\"\"\n",
    "        return A * (1 - np.exp(-t / tau))\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for series_idx in range(n_series):\n",
    "        try:\n",
    "            # Get intensity data for this series\n",
    "            intensity_data = intensity_array[series_idx, :]\n",
    "            \n",
    "            # Find the index of minimum intensity (start of recovery)\n",
    "            min_idx = np.argmin(intensity_data)\n",
    "            if min_idx > 15:\n",
    "                min_idx = 15            \n",
    "            \n",
    "            # Extract data starting from minimum intensity\n",
    "            recovery_data = intensity_data[min_idx:]\n",
    "            recovery_timepoints = np.arange(len(recovery_data))\n",
    "            \n",
    "            # Shift data so it starts from zero (subtract minimum value)\n",
    "            min_intensity = recovery_data[0]\n",
    "            shifted_data = recovery_data - min_intensity\n",
    "            \n",
    "            # Initial parameter guesses\n",
    "            # A: approximate plateau height (max - min of recovery data)\n",
    "            A_guess = np.max(shifted_data) if np.max(shifted_data) > 0 else 1.0\n",
    "            \n",
    "            # tau: rough estimate based on when we reach ~63% of plateau\n",
    "            # Find where signal reaches 63% of max\n",
    "            target_value = 0.63 * A_guess\n",
    "            tau_guess = 1.0\n",
    "            if A_guess > 0:\n",
    "                # Find approximate tau from data\n",
    "                above_target = np.where(shifted_data >= target_value)[0]\n",
    "                if len(above_target) > 0:\n",
    "                    tau_guess = float(above_target[0])\n",
    "                else:\n",
    "                    tau_guess = len(recovery_timepoints) / 3.0\n",
    "            \n",
    "            # Set reasonable bounds for parameters\n",
    "            # A should be positive and not too much larger than data range\n",
    "            A_bounds = (0, 5 * A_guess if A_guess > 0 else 10)\n",
    "            # tau should be positive and reasonable given time scale\n",
    "            tau_bounds = (0.1, 10 * len(recovery_timepoints))\n",
    "            \n",
    "            bounds = ([A_bounds[0], tau_bounds[0]], \n",
    "                     [A_bounds[1], tau_bounds[1]])\n",
    "            \n",
    "            # Perform the fit\n",
    "            popt, pcov = curve_fit(\n",
    "                recovery_function, \n",
    "                recovery_timepoints, \n",
    "                shifted_data,\n",
    "                p0=[A_guess, tau_guess],\n",
    "                bounds=bounds,\n",
    "                maxfev=5000\n",
    "            )\n",
    "            \n",
    "            A_fit, tau_fit = popt\n",
    "            \n",
    "            # Generate fitted curve\n",
    "            fitted_curve = recovery_function(recovery_timepoints, A_fit, tau_fit)\n",
    "            \n",
    "            # Add back the minimum intensity to get absolute values\n",
    "            fitted_curve_absolute = fitted_curve + min_intensity\n",
    "            \n",
    "            # Calculate fit statistics\n",
    "            ss_res = np.sum((shifted_data - fitted_curve) ** 2)\n",
    "            ss_tot = np.sum((shifted_data - np.mean(shifted_data)) ** 2)\n",
    "            r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "            \n",
    "            rmse = np.sqrt(np.mean((shifted_data - fitted_curve) ** 2))\n",
    "            param_errors = np.sqrt(np.diag(pcov))\n",
    "\n",
    "            # correct for actual time interval so that tau is expressed in seconds\n",
    "            tau_fit = tau_fit * time_interval\n",
    "            param_errors[1] = param_errors[1] * time_interval # I am not quite sure this is correct\n",
    "            \n",
    "            # Store results\n",
    "            series_result = {\n",
    "                'A': A_fit,\n",
    "                'tau': tau_fit,\n",
    "                'min_intensity': min_intensity,\n",
    "                'min_index': min_idx,\n",
    "                'r_squared': r_squared,\n",
    "                'rmse': rmse,\n",
    "                'parameter_errors': param_errors,\n",
    "                'recovery_timepoints': recovery_timepoints,\n",
    "                'recovery_data': recovery_data,\n",
    "                'fitted_curve': fitted_curve_absolute,\n",
    "                'shifted_data': shifted_data,\n",
    "                'fitted_curve_shifted': fitted_curve\n",
    "            }\n",
    "            \n",
    "            if return_stats:\n",
    "                series_result.update({\n",
    "                    'covariance_matrix': pcov,\n",
    "                    'initial_guess': [A_guess, tau_guess],\n",
    "                    'bounds_used': bounds\n",
    "                })\n",
    "            \n",
    "            results[f'series_{series_idx}'] = series_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Fitting failed for series {series_idx}: {str(e)}\")\n",
    "            results[f'series_{series_idx}'] = {\n",
    "                'error': str(e),\n",
    "                'A': np.nan,\n",
    "                'tau': np.nan,\n",
    "                'r_squared': np.nan\n",
    "            }\n",
    "    \n",
    "    # Create plots if requested\n",
    "    if plot_results:\n",
    "        plot_recovery_fits(intensity_array, results, time_interval, 20, (0.3, 1.1))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_recovery_fits(intensity_array, results, time_interval, max_plots=6,  y_lim: Tuple[int, int] = (0.4, 1.2)):\n",
    "    \"\"\"Plot the recovery fits for visualization\"\"\"\n",
    "    plotFitParameters = False\n",
    "    \n",
    "    n_series = intensity_array.shape[0]\n",
    "    n_plots = min(n_series, max_plots)\n",
    "    n_plot_rows = math.ceil(n_plots / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_plot_rows, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        ax = axes[i]\n",
    "        series_key = f'series_{i}'\n",
    "        \n",
    "        if series_key not in results or 'error' in results[series_key]:\n",
    "            ax.text(0.5, 0.5, f'Series {i}\\nFit Failed', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            continue\n",
    "        \n",
    "        result = results[series_key]\n",
    "        \n",
    "        # Plot original data\n",
    "        original_time = np.arange(intensity_array.shape[1])\n",
    "        original_time = original_time * time_interval\n",
    "        ax.plot(original_time, intensity_array[i, :], 'b.-', alpha=0.7, \n",
    "                label='Original Data', markersize=3)\n",
    "        \n",
    "        # Highlight recovery portion\n",
    "        min_idx = result['min_index']\n",
    "        recovery_time = original_time[min_idx:]\n",
    "        \n",
    "        ax.plot(recovery_time, result['fitted_curve'], 'r-', \n",
    "                linewidth=2, label='Recovery Fit')\n",
    "        \n",
    "        # Mark minimum point\n",
    "        ax.axvline(x=min_idx, color='gray', linestyle='--', alpha=0.5, \n",
    "                  label='Recovery Start')\n",
    "        \n",
    "        # Add fit parameters to plot\n",
    "        if plotFitParameters:\n",
    "            A, tau = result['A'], result['tau']\n",
    "            r2 = result['r_squared']\n",
    "            textstr = f'A = {A:.2f}\\nτ = {tau:.2f}\\nR² = {r2:.3f}'\n",
    "            ax.text(0.05, 0.95, textstr, transform=ax.transAxes, \n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                    facecolor='wheat', alpha=0.8), fontsize=9)\n",
    "        \n",
    "        ax.set_title(f'Series {i}')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Intensity')\n",
    "        ax.set_ylim(y_lim)\n",
    "        # ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_plots, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa87229b-4567-4ba6-9359-d49e5f61344a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def summarize_fits(results, name):\n",
    "    \"\"\"Create a summary DataFrame of all fits and optionally print summary\"\"\"\n",
    "    print(\"=\"*120)\n",
    "    print(\"RECOVERY FUNCTION FIT SUMMARY FOR \" + name)\n",
    "    print(\"=\"*120)\n",
    "    print(f\"{name:<20} {'Series':<8} {'A (Plateau)':<12} {'Min Intensity':<14} {'τ (Time-s)':<12} {'Mobile Fraction':<16} {'R²':<8} {'Status'}\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    # Lists to store DataFrame data\n",
    "    df_data = []\n",
    "    successful_fits = 0\n",
    "    A_values = []\n",
    "    tau_values = []\n",
    "    mobile_fractions = []\n",
    "    \n",
    "    for series_key, result in results.items():\n",
    "        series_num = series_key.split('_')[1]\n",
    "        \n",
    "        if 'error' in result:\n",
    "            print(f\"{name:<20} {series_num:<8} {'Failed':<12} {'Failed':<14} {'--':<12} {'--':<16} {'--':<8} Error\")\n",
    "            # Add failed fit to DataFrame\n",
    "            df_data.append({\n",
    "                'Name': name,\n",
    "                'Series': series_num,\n",
    "                'A (Plateau)': None,\n",
    "                'Min Intensity': None,\n",
    "                'τ (Time-s)': None,\n",
    "                'Mobile Fraction': None,\n",
    "                'R²': None,\n",
    "                'Status': 'Error'\n",
    "            })\n",
    "        else:\n",
    "            A, tau, r2, min_intensity = result['A'], result['tau'], result['r_squared'], result['min_intensity']\n",
    "            mobile_fraction = result['A'] / (1.0 - min_intensity)\n",
    "            print(f\"{name:<20} {series_num:<8} {A:<12.3f} {min_intensity:<14.3f} {tau:<12.3f} {mobile_fraction:<16.3f} {r2:<8.3f} OK\")\n",
    "            \n",
    "            # Add successful fit to DataFrame\n",
    "            df_data.append({\n",
    "                'Name': name,\n",
    "                'Series': series_num,\n",
    "                'A (Plateau)': A,\n",
    "                'Min Intensity': min_intensity,\n",
    "                'τ (Time-s)': tau,\n",
    "                'Mobile Fraction': mobile_fraction,\n",
    "                'R²': r2,\n",
    "                'Status': 'OK'\n",
    "            })\n",
    "            \n",
    "            successful_fits += 1\n",
    "            A_values.append(A)\n",
    "            tau_values.append(tau)\n",
    "            mobile_fractions.append(mobile_fraction)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    # Print summary statistics (keeping original behavior)\n",
    "    if successful_fits > 0:\n",
    "        print(\"-\"*120)\n",
    "        print(f\"Successful fits: {successful_fits}/{len(results)}\")\n",
    "        print(f\"Average A: {np.mean(A_values):.3f} ± {np.std(A_values):.3f}\")\n",
    "        print(f\"Average τ: {np.mean(tau_values):.3f} ± {np.std(tau_values):.3f}\")\n",
    "        print(f\"Average Mobile Fraction: {np.mean(mobile_fractions):.3f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Alternative version if you want to suppress print output and only return DataFrame\n",
    "def summarize_fits_df_only(results, name):\n",
    "    \"\"\"Create a summary DataFrame of all fits without printing\"\"\"\n",
    "    df_data = []\n",
    "    \n",
    "    for series_key, result in results.items():\n",
    "        series_num = series_key.split('_')[1]\n",
    "        \n",
    "        if 'error' in result:\n",
    "            df_data.append({\n",
    "                'Name': name,\n",
    "                'Series': series_num,\n",
    "                'A (Plateau)': None,\n",
    "                'Min Intensity': None,\n",
    "                'τ (Time-s)': None,\n",
    "                'Mobile Fraction': None,\n",
    "                'R²': None,\n",
    "                'Status': 'Error'\n",
    "            })\n",
    "        else:\n",
    "            A, tau, r2, min_intensity = result['A'], result['tau'], result['r_squared'], result['min_intensity']\n",
    "            mobile_fraction = result['A'] / (1.0 - min_intensity)\n",
    "            \n",
    "            df_data.append({\n",
    "                'Name': name,\n",
    "                'Series': series_num,\n",
    "                'A (Plateau)': A,\n",
    "                'Min Intensity': min_intensity,\n",
    "                'τ (Time-s)': tau,\n",
    "                'Mobile Fraction': mobile_fraction,\n",
    "                'R²': r2,\n",
    "                'Status': 'OK'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a142604-6f24-4060-a8c2-2a47fbb43d74",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_fit_recovery_function(): # Example usage and testing\n",
    "    # Generate synthetic recovery data\n",
    "    np.random.seed(42)\n",
    "    n_series = 6\n",
    "    n_timepoints = 50\n",
    "    \n",
    "    # Create synthetic data with recovery pattern\n",
    "    synthetic_data = np.zeros((n_series, n_timepoints))\n",
    "    \n",
    "    for i in range(n_series):\n",
    "        # True parameters for each series\n",
    "        true_A = 80 + np.random.normal(0, 10)  # Plateau around 80\n",
    "        true_tau = 8 + np.random.normal(0, 2)   # Time constant around 8\n",
    "        baseline = 20 + np.random.normal(0, 5)  # Baseline around 20\n",
    "        \n",
    "        # Recovery starts at random point (simulating bleaching then recovery)\n",
    "        recovery_start = np.random.randint(5, 15)\n",
    "        \n",
    "        time_points = np.arange(n_timepoints)\n",
    "        \n",
    "        # Before recovery: high intensity with some decay\n",
    "        pre_recovery = baseline + true_A * np.exp(-(time_points[:recovery_start])/5)\n",
    "        \n",
    "        # Recovery phase: exponential recovery\n",
    "        recovery_time = time_points[recovery_start:] - recovery_start\n",
    "        recovery_phase = baseline + true_A * (1 - np.exp(-recovery_time / true_tau))\n",
    "        \n",
    "        # Combine phases\n",
    "        full_signal = np.concatenate([pre_recovery, recovery_phase])\n",
    "        \n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, 3, n_timepoints)\n",
    "        synthetic_data[i, :] = full_signal + noise\n",
    "    \n",
    "    print(\"Generated synthetic recovery data\")\n",
    "    print(f\"Data shape: {synthetic_data.shape}\")\n",
    "    print()\n",
    "    \n",
    "    # Fit the recovery functions\n",
    "    results = fit_recovery_function(\n",
    "        synthetic_data, \n",
    "        return_stats=True, \n",
    "        plot_results=True\n",
    "    )\n",
    "    \n",
    "    # Print summary\n",
    "    summarize_fits(results)\n",
    "    \n",
    "    # Show individual series details\n",
    "    print(\"\\nDetailed Results for First 3 Series:\")\n",
    "    for i in range(min(3, len(results))):\n",
    "        series_key = f'series_{i}'\n",
    "        if series_key in results and 'error' not in results[series_key]:\n",
    "            result = results[series_key]\n",
    "            print(f\"\\nSeries {i}:\")\n",
    "            print(f\"  Plateau (A): {result['A']:.3f} ± {result['parameter_errors'][0]:.3f}\")\n",
    "            print(f\"  Time constant (τ): {result['tau']:.3f} ± {result['parameter_errors'][1]:.3f}\")\n",
    "            print(f\"  Recovery starts at index: {result['min_index']}\")\n",
    "            print(f\"  Minimum intensity: {result['min_intensity']:.3f}\")\n",
    "            print(f\"  R²: {result['r_squared']:.4f}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea9658-4787-4c29-9323-77ae69aecb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe392a2e-260a-49f0-9de1-f0907faa4288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
